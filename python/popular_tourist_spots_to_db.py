import os
import pandas as pd
import mysql.connector
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
import logging
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PopularTouristSpotsImporter:
    def __init__(self):
        """ì´ˆê¸°í™” ë° í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        load_dotenv()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'user': os.getenv('DB_USERNAME', 'root'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'safe_walk'),
            'charset': os.getenv('DB_CHARSET', 'utf8mb4')
        }
        
        # SQLAlchemy ì—”ì§„ ìƒì„±
        connection_string = f"mysql+mysqlconnector://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}?charset={self.db_config['charset']}"
        self.engine = create_engine(connection_string)
        
        # CSV ì»¬ëŸ¼ ë§¤í•‘ (ì‹¤ì œ CSV ì»¬ëŸ¼ëª… ê¸°ì¤€)
        self.column_mapping = {
            'ìˆœìœ„': 'rank',
            'ê´€ê´‘ì§€ID': 'tourist_spot_id',
            'ê´€ì‹¬ì§€ì ëª…': 'spot_name',
            'êµ¬ë¶„': 'category',
            'ì—°ë ¹ëŒ€': 'age_group',
            'ë¹„ìœ¨': 'ratio',
            'ê¸°ì¤€ë…„ì›”': 'base_year_month',
            'ì‹œë„ëª…': 'sido_name',
            'ì‹œêµ°êµ¬ëª…': 'sigungu_name',
            'ì„±ì¥ìœ¨': 'growth_rate'
        }

    def create_table(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±"""
        try:
            print("ğŸ—ï¸ ì¸ê¸°ê´€ê´‘ì§€ í…Œì´ë¸” ìƒì„± ì¤‘...")
            
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS popular_tourist_spots (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                sido_name VARCHAR(50) COMMENT 'ê´‘ì—­ì‹œ/ë„ëª…',
                sigungu_name VARCHAR(50) COMMENT 'ì‹œ/êµ°/êµ¬ëª…',
                spot_name VARCHAR(200) COMMENT 'ì¸ê¸°ê´€ê´‘ì§€ëª…',
                tourist_spot_id VARCHAR(100) COMMENT 'ê´€ê´‘ì§€ID',
                category VARCHAR(100) COMMENT 'êµ¬ë¶„',
                age_group VARCHAR(20) COMMENT 'ì—°ë ¹ëŒ€',
                ratio DECIMAL(5,2) COMMENT 'ë¹„ìœ¨',
                base_year_month VARCHAR(10) COMMENT 'ê¸°ì¤€ë…„ì›”',
                growth_rate DECIMAL(5,2) COMMENT 'ì„±ì¥ìœ¨',
                source_file VARCHAR(100) COMMENT 'ì¶œì²˜íŒŒì¼',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_sido (sido_name),
                INDEX idx_sigungu (sigungu_name),
                INDEX idx_spot_name (spot_name),
                INDEX idx_category (category),
                INDEX idx_tourist_spot_id (tourist_spot_id),
                INDEX idx_location (sido_name, sigungu_name)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='ì¸ê¸°ê´€ê´‘ì§€ ë°ì´í„°';
            """
            
            with self.engine.connect() as connection:
                connection.execute(text(create_table_sql))
                connection.commit()
            
            print("âœ… ì¸ê¸°ê´€ê´‘ì§€ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def load_csv_data(self, csv_path, source_file):
        """CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        try:
            print(f"ğŸ“ CSV íŒŒì¼ ë¡œë“œ ì¤‘: {csv_path}")
            
            # CSV íŒŒì¼ ì½ê¸° (í•œê¸€ ì¸ì½”ë”© ì²˜ë¦¬)
            df = pd.read_csv(csv_path, encoding='utf-8')
            
            print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
            print(f"ğŸ“‹ ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)}")
            
            # ì»¬ëŸ¼ëª… ë³€ê²½
            df = df.rename(columns=self.column_mapping)
            
            # ì¶œì²˜ íŒŒì¼ ì •ë³´ ì¶”ê°€
            df['source_file'] = source_file
            
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            try:
                # ìˆ«ìí˜• ì»¬ëŸ¼ ì²˜ë¦¬
                numeric_columns = ['ratio', 'growth_rate']
                
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
                # ë¬¸ìì—´ ì»¬ëŸ¼ ì²˜ë¦¬ (ë¹ˆ ê°’ì€ Noneìœ¼ë¡œ ë³€í™˜)
                string_columns = ['sido_name', 'sigungu_name', 'spot_name', 'tourist_spot_id', 
                                'category', 'age_group', 'base_year_month']
                for col in string_columns:
                    if col in df.columns:
                        df[col] = df[col].replace('', None)
                
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜ (MySQLì—ì„œ ì˜¤ë¥˜ ë°©ì§€)
            df = df.where(pd.notnull(df), None)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
            required_columns = [
                'sido_name', 'sigungu_name', 'spot_name', 'tourist_spot_id',
                'category', 'age_group', 'ratio', 'base_year_month', 
                'growth_rate', 'source_file'
            ]
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            existing_columns = [col for col in required_columns if col in df.columns]
            df = df[existing_columns]
            
            print(f"ğŸ” ì „ì²˜ë¦¬ í›„ ë°ì´í„° í˜•íƒœ: {df.shape}")
            print(f"ğŸ” ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼: {list(df.columns)}")
            
            # ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
            print(f"ğŸ“Š ì „ì²˜ë¦¬ í›„ ë°ì´í„° ìƒ˜í”Œ:")
            sample_data = df.head(5)
            for idx, row in sample_data.iterrows():
                if 'sido_name' in df.columns and 'sigungu_name' in df.columns:
                    print(f"   {row['sido_name']} {row['sigungu_name']} | {row['spot_name']} | {row['category']}")
                else:
                    print(f"   {row['spot_name']} | {row['category']}")
            
            return df
            
        except Exception as e:
            print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def merge_and_process_data(self, df1, df2):
        """ë‘ CSV ë°ì´í„°ë¥¼ ë³‘í•©í•˜ê³  ì²˜ë¦¬"""
        try:
            print("ğŸ”„ ë°ì´í„° ë³‘í•© ë° ì²˜ë¦¬ ì¤‘...")
            
            # ì²« ë²ˆì§¸ CSV (ì„¸ëŒ€ë³„ ì¸ê¸°ê´€ê´‘ì§€)ì— ì‹œë„/ì‹œêµ°êµ¬ ì •ë³´ ì¶”ê°€
            # ê²½ìƒë¶ë„ ê²½ì£¼ì‹œë¡œ ì„¤ì •
            df1['sido_name'] = 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
            df1['sigungu_name'] = 'ì œì£¼ì‹œ'
            df1['base_year_month'] = None
            df1['growth_rate'] = None
            
            # ë‘ ë²ˆì§¸ CSV (ì„¸ëŒ€ë³„ í•«í”Œë ˆì´ìŠ¤)ì— ratio ì»¬ëŸ¼ ì¶”ê°€ (ê¸°ë³¸ê°’ 0)
            df2['ratio'] = 0
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ í†µì¼ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
            df1_columns = ['sido_name', 'sigungu_name', 'spot_name', 'tourist_spot_id', 
                          'category', 'age_group', 'ratio', 'base_year_month', 
                          'growth_rate', 'source_file']
            
            df2_columns = ['sido_name', 'sigungu_name', 'spot_name', 'tourist_spot_id', 
                          'category', 'age_group', 'ratio', 'base_year_month', 
                          'growth_rate', 'source_file']
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            df1_processed = df1[[col for col in df1_columns if col in df1.columns]]
            df2_processed = df2[[col for col in df2_columns if col in df2.columns]]
            
            # ë‘ ë°ì´í„°í”„ë ˆì„ ë³‘í•©
            merged_df = pd.concat([df1_processed, df2_processed], ignore_index=True)
            
            print(f"ğŸ“Š ë³‘í•© í›„ ë°ì´í„° í˜•íƒœ: {merged_df.shape}")
            print(f"ğŸ“Š ë³‘í•© í›„ ì»¬ëŸ¼: {list(merged_df.columns)}")
            print(f"ğŸ“Š ë³‘í•© í›„ ë°ì´í„° ìƒ˜í”Œ:")
            sample_data = merged_df.head(10)
            for idx, row in sample_data.iterrows():
                print(f"   {row['sido_name']} {row['sigungu_name']} | {row['spot_name']} | {row['category']} | {row['source_file']}")
            
            return merged_df
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë³‘í•© ì‹¤íŒ¨: {e}")
            raise

    def save_to_database(self, df, replace_all=False):
        """ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
            
            if replace_all:
                # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì „ì²´ êµì²´ ëª¨ë“œ)
                print("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
                with self.engine.connect() as connection:
                    connection.execute(text("DELETE FROM popular_tourist_spots"))
                    connection.commit()
                print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
            else:
                # ì¤‘ë³µ ë°ì´í„° í™•ì¸ ë° ì œê±°
                print("ğŸ” ì¤‘ë³µ ë°ì´í„° í™•ì¸ ì¤‘...")
                with self.engine.connect() as connection:
                    for _, row in df.iterrows():
                        delete_sql = """
                        DELETE FROM popular_tourist_spots 
                        WHERE spot_name = :spot_name AND source_file = :source_file
                        """
                        connection.execute(text(delete_sql), 
                                         {
                                             'spot_name': row['spot_name'], 
                                             'source_file': row['source_file']
                                         })
                    connection.commit()
                print("âœ… ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
            
            # í…Œì´ë¸”ì— ë°ì´í„° ì‚½ì…
            df.to_sql('popular_tourist_spots', 
                     con=self.engine, 
                     if_exists='append', 
                     index=False, 
                     method='multi',
                     chunksize=1000)
            
            print(f"âœ… {len(df)}ê±´ì˜ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì €ì¥ëœ ë°ì´í„° í™•ì¸
            with self.engine.connect() as connection:
                result = connection.execute(text("SELECT COUNT(*) as total FROM popular_tourist_spots"))
                total_count = result.fetchone()[0]
                print(f"ğŸ“Š ì´ ì €ì¥ëœ ë°ì´í„°: {total_count}ê±´")
                
                # ì‹œë„ë³„ ë°ì´í„° ìˆ˜ í™•ì¸
                sido_count_sql = """
                SELECT sido_name, COUNT(*) as count 
                FROM popular_tourist_spots 
                GROUP BY sido_name 
                ORDER BY count DESC
                """
                sido_result = connection.execute(text(sido_count_sql))
                print(f"ğŸ“Š ì‹œë„ë³„ ë°ì´í„° ìˆ˜:")
                for row in sido_result:
                    print(f"   {row[0]}: {row[1]}ê±´")
                
                # ì¶œì²˜ íŒŒì¼ë³„ ë°ì´í„° ìˆ˜ í™•ì¸
                source_count_sql = """
                SELECT source_file, COUNT(*) as count 
                FROM popular_tourist_spots 
                GROUP BY source_file 
                ORDER BY count DESC
                """
                source_result = connection.execute(text(source_count_sql))
                print(f"ğŸ“Š ì¶œì²˜ íŒŒì¼ë³„ ë°ì´í„° ìˆ˜:")
                for row in source_result:
                    print(f"   {row[0]}: {row[1]}ê±´")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def run_import(self, csv_path1, csv_path2):
        """ì „ì²´ ì„í¬íŠ¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            print("ğŸš€ ì¸ê¸°ê´€ê´‘ì§€ ë°ì´í„° ì„í¬íŠ¸ ì‹œì‘")
            print("=" * 50)
            
            # # 1. í…Œì´ë¸” ìƒì„±
            # self.create_table()
            
            # 2. ì²« ë²ˆì§¸ CSV ë°ì´í„° ë¡œë“œ (ì„¸ëŒ€ë³„ ì¸ê¸°ê´€ê´‘ì§€)
            df1 = self.load_csv_data(csv_path1, "ì„¸ëŒ€ë³„ ì¸ê¸°ê´€ê´‘ì§€(ì „ì²´)")
            
            # 3. ë‘ ë²ˆì§¸ CSV ë°ì´í„° ë¡œë“œ (ì„¸ëŒ€ë³„ í•«í”Œë ˆì´ìŠ¤)
            df2 = self.load_csv_data(csv_path2, "ì„¸ëŒ€ë³„ í•«í”Œë ˆì´ìŠ¤(ì „ì²´)")
            
            # 4. ë°ì´í„° ë³‘í•© ë° ì²˜ë¦¬
            merged_df = self.merge_and_process_data(df1, df2)
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì¶”ê°€ ëª¨ë“œ)
            self.save_to_database(merged_df, replace_all=False)
            
            print("=" * 50)
            print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì„í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            raise

    def run_import_replace_all(self, csv_path1, csv_path2):
        """ì „ì²´ ì„í¬íŠ¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ì „ì²´ êµì²´ ëª¨ë“œ)"""
        try:
            print("ğŸš€ ì¸ê¸°ê´€ê´‘ì§€ ë°ì´í„° ì„í¬íŠ¸ ì‹œì‘ (ì „ì²´ êµì²´ ëª¨ë“œ)")
            print("=" * 50)
            
            # 1. í…Œì´ë¸” ìƒì„±
            self.create_table()
            
            # 2. ì²« ë²ˆì§¸ CSV ë°ì´í„° ë¡œë“œ (ì„¸ëŒ€ë³„ ì¸ê¸°ê´€ê´‘ì§€)
            df1 = self.load_csv_data(csv_path1, "ì„¸ëŒ€ë³„ ì¸ê¸°ê´€ê´‘ì§€(ì „ì²´)")
            
            # 3. ë‘ ë²ˆì§¸ CSV ë°ì´í„° ë¡œë“œ (ì„¸ëŒ€ë³„ í•«í”Œë ˆì´ìŠ¤)
            df2 = self.load_csv_data(csv_path2, "ì„¸ëŒ€ë³„ í•«í”Œë ˆì´ìŠ¤(ì „ì²´)")
            
            # 4. ë°ì´í„° ë³‘í•© ë° ì²˜ë¦¬
            merged_df = self.merge_and_process_data(df1, df2)
            
            # 5. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì „ì²´ êµì²´ ëª¨ë“œ)
            self.save_to_database(merged_df, replace_all=True)
            
            print("=" * 50)
            print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì„í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì „ì²´ êµì²´)")
            
        except Exception as e:
            print(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            raise

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # CSV íŒŒì¼ ê²½ë¡œ
        csv_path1 = "csv/20250817000730_ì„¸ëŒ€ë³„ ì¸ê¸°ê´€ê´‘ì§€(ì „ì²´).csv"
        csv_path2 = "csv/20250817000736_ì„¸ëŒ€ë³„ í•«í”Œë ˆì´ìŠ¤(ì „ì²´).csv"
        
        # ì‚¬ìš©ì ëª¨ë“œ ì„ íƒ
        print("ğŸ“ ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ì¶”ê°€ ëª¨ë“œ (ê¸°ì¡´ ë°ì´í„° ìœ ì§€í•˜ê³  ìƒˆ ë°ì´í„° ì¶”ê°€)")
        print("2. ì „ì²´ êµì²´ ëª¨ë“œ (ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆ ë°ì´í„°ë¡œ êµì²´)")
        
        choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()
        
        # ì„í¬í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        importer = PopularTouristSpotsImporter()
        
        if choice == "1":
            print("âœ… ì¶”ê°€ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            importer.run_import(csv_path1, csv_path2)
        elif choice == "2":
            print("âœ… ì „ì²´ êµì²´ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            importer.run_import_replace_all(csv_path1, csv_path2)
        else:
            print("âš ï¸ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’(ì¶”ê°€ ëª¨ë“œ)ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            importer.run_import(csv_path1, csv_path2)
        
    except Exception as e:
        print(f"âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
