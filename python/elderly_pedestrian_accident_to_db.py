import os
import pandas as pd
import mysql.connector
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
import logging
import json

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ElderlyPedestrianAccidentImporter:
    def __init__(self):
        """ì´ˆê¸°í™” ë° í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        load_dotenv()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'user': os.getenv('DB_USERNAME', 'root'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'safe_walk'),
            'charset': os.getenv('DB_CHARSET', 'utf8mb4')
        }
        
        # SQLAlchemy ì—”ì§„ ìƒì„±
        connection_string = f"mysql+mysqlconnector://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}?charset={self.db_config['charset']}"
        self.engine = create_engine(connection_string)
        
        # CSV ì»¬ëŸ¼ ë§¤í•‘ (ì‹¤ì œ CSV ì»¬ëŸ¼ëª… ê¸°ì¤€)
        self.column_mapping = {
            'ì‚¬ê³ ë‹¤ë°œì§€fid': 'accident_hotspot_fid',
            'ì‚¬ê³ ë‹¤ë°œì§€id': 'accident_hotspot_id',
            'ë²•ì •ë™ì½”ë“œ': 'sido_code',
            'ì§€ì ì½”ë“œ': 'point_code',
            'ì‹œë„ì‹œêµ°êµ¬ëª…': 'sido_sigungu_name',
            'ì§€ì ëª…': 'point_name',
            'ì‚¬ê³ ê±´ìˆ˜': 'accident_count',
            'ì‚¬ìƒììˆ˜': 'casualty_count',
            'ì‚¬ë§ììˆ˜': 'death_count',
            'ì¤‘ìƒììˆ˜': 'serious_injury_count',
            'ê²½ìƒììˆ˜': 'minor_injury_count',
            'ë¶€ìƒì‹ ê³ ììˆ˜': 'injury_report_count',
            'ê²½ë„': 'longitude',
            'ìœ„ë„': 'latitude',
            'ë‹¤ë°œì§€ì—­í´ë¦¬ê³¤': 'hotspot_polygon'
        }
        
        # Sido ì½”ë“œ ë§¤í•‘
        self.sido_mapping = {
            '1100': 'ì„œìš¸íŠ¹ë³„ì‹œ',
            '1200': 'ë¶€ì‚°ê´‘ì—­ì‹œ',
            '2200': 'ëŒ€êµ¬ê´‘ì—­ì‹œ',
            '2300': 'ì¸ì²œê´‘ì—­ì‹œ',
            '2400': 'ê´‘ì£¼ê´‘ì—­ì‹œ',
            '2500': 'ëŒ€ì „ê´‘ì—­ì‹œ',
            '2600': 'ìš¸ì‚°ê´‘ì—­ì‹œ',
            '2700': 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ',
            '1300': 'ê²½ê¸°ë„',
            '1400': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
            '1500': 'ì¶©ì²­ë¶ë„',
            '1600': 'ì¶©ì²­ë‚¨ë„',
            '1700': 'ì „ë¶íŠ¹ë³„ìì¹˜ë„',
            '1800': 'ì „ë¼ë‚¨ë„',
            '1900': 'ê²½ìƒë¶ë„',
            '2000': 'ê²½ìƒë‚¨ë„',
            '2100': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„'
        }

    def create_table(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±"""
        try:
            print("ğŸ—ï¸ ë…¸ì¸ ë³´í–‰ì ì‚¬ê³  ë‹¤ë°œì§€ í…Œì´ë¸” ìƒì„± ì¤‘...")
            
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS elderly_pedestrian_accident_hotspots (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                accident_hotspot_fid BIGINT NOT NULL COMMENT 'ì‚¬ê³ ë‹¤ë°œì§€fid',
                accident_hotspot_id BIGINT NOT NULL COMMENT 'ì‚¬ê³ ë‹¤ë°œì§€id',
                sido_code VARCHAR(10) NOT NULL COMMENT 'ë²•ì •ë™ì½”ë“œ',
                point_code VARCHAR(20) NOT NULL COMMENT 'ì§€ì ì½”ë“œ',
                sido_sigungu_name VARCHAR(100) NOT NULL COMMENT 'ì‹œë„ì‹œêµ°êµ¬ëª…',
                point_name TEXT COMMENT 'ì§€ì ëª…',
                legal_dong VARCHAR(50) COMMENT 'ë²•ì •ë™',
                accident_count INT COMMENT 'ì‚¬ê³ ê±´ìˆ˜',
                casualty_count INT COMMENT 'ì‚¬ìƒììˆ˜',
                death_count INT COMMENT 'ì‚¬ë§ììˆ˜',
                serious_injury_count INT COMMENT 'ì¤‘ìƒììˆ˜',
                minor_injury_count INT COMMENT 'ê²½ìƒììˆ˜',
                injury_report_count INT COMMENT 'ë¶€ìƒì‹ ê³ ììˆ˜',
                longitude DECIMAL(12,9) COMMENT 'ê²½ë„',
                latitude DECIMAL(12,9) COMMENT 'ìœ„ë„',
                hotspot_polygon JSON COMMENT 'ë‹¤ë°œì§€ì—­í´ë¦¬ê³¤',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_hotspot_fid (accident_hotspot_fid),
                INDEX idx_hotspot_id (accident_hotspot_id),
                INDEX idx_sido_code (sido_code),
                INDEX idx_point_code (point_code),
                INDEX idx_legal_dong (legal_dong),
                INDEX idx_location (longitude, latitude),
                UNIQUE KEY uk_hotspot_fid (accident_hotspot_fid)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='ë…¸ì¸ ë³´í–‰ì ì‚¬ê³  ë‹¤ë°œì§€ ë°ì´í„°';
            """
            
            with self.engine.connect() as connection:
                connection.execute(text(create_table_sql))
                connection.commit()
            
            print("âœ… ë…¸ì¸ ë³´í–‰ì ì‚¬ê³  ë‹¤ë°œì§€ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
            # ê¸°ì¡´ í…Œì´ë¸”ì— ë²•ì •ë™ ì¹¼ëŸ¼ì´ ì—†ë‹¤ë©´ ì¶”ê°€
            self.add_legal_dong_column()
            
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def add_legal_dong_column(self):
        """ê¸°ì¡´ í…Œì´ë¸”ì— ë²•ì •ë™ ì¹¼ëŸ¼ ì¶”ê°€"""
        try:
            print("ğŸ”§ ë²•ì •ë™ ì¹¼ëŸ¼ ì¶”ê°€ í™•ì¸ ì¤‘...")
            
            # í…Œì´ë¸” êµ¬ì¡° í™•ì¸
            check_column_sql = """
            SELECT COLUMN_NAME 
            FROM INFORMATION_SCHEMA.COLUMNS 
            WHERE TABLE_SCHEMA = :database 
            AND TABLE_NAME = 'elderly_pedestrian_accident_hotspots' 
            AND COLUMN_NAME = 'legal_dong'
            """
            
            with self.engine.connect() as connection:
                result = connection.execute(text(check_column_sql), 
                                         {"database": self.db_config['database']})
                column_exists = result.fetchone() is not None
                
                if not column_exists:
                    print("â• ë²•ì •ë™ ì¹¼ëŸ¼ ì¶”ê°€ ì¤‘...")
                    
                    add_column_sql = """
                    ALTER TABLE elderly_pedestrian_accident_hotspots 
                    ADD COLUMN legal_dong VARCHAR(50) COMMENT 'ë²•ì •ë™' AFTER point_name
                    """
                    
                    connection.execute(text(add_column_sql))
                    connection.commit()
                    
                    # ì¸ë±ìŠ¤ ì¶”ê°€
                    add_index_sql = """
                    ALTER TABLE elderly_pedestrian_accident_hotspots 
                    ADD INDEX idx_legal_dong (legal_dong)
                    """
                    
                    connection.execute(text(add_index_sql))
                    connection.commit()
                    
                    print("âœ… ë²•ì •ë™ ì¹¼ëŸ¼ ì¶”ê°€ ì™„ë£Œ")
                else:
                    print("âœ… ë²•ì •ë™ ì¹¼ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
                    
        except Exception as e:
            print(f"âš ï¸ ë²•ì •ë™ ì¹¼ëŸ¼ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")

    def extract_legal_dong(self, point_name):
        """
        ì§€ì ëª…ì—ì„œ ë²•ì •ë™ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
        
        ì˜ˆì‹œ:
        - "ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ì¢…ë¡œ2ê°€(ì¢…ë¡œ2ê°€êµì°¨ë¡œ ë¶€ê·¼)" -> "ì¢…ë¡œ2ê°€"
        - "ì„œìš¸íŠ¹ë³„ì‹œ ë™ëŒ€ë¬¸êµ¬ ì œê¸°ë™(ìš©ë‘êµ ë¶€ê·¼)" -> "ì œê¸°ë™"
        - "ê²½ê¸°ë„ ê³ ì–‘ì‹œ ì¼ì‚°ë™êµ¬ ë§ˆë‘ë™(ì–‘ì£¼ì£¼ì°¨íƒ€ì›Œì• ì¸ê·¼)" -> "ë§ˆë‘ë™"
        - "ì¶©ë‚¨ ì„œì‚°ì‹œ ìë‚´ë™(ë¶€ì¶˜ë™ì£¼ë¯¼ìì¹˜ì„¼í„° ë¶€ê·¼)" -> "ìë‚´ë™"
        """
        try:
            if pd.isna(point_name) or point_name == '':
                return None
            
            # ê´„í˜¸ê°€ ìˆëŠ”ì§€ í™•ì¸
            if '(' not in point_name:
                return None
            
            # ê´„í˜¸ ì•ë¶€ë¶„ì„ ì¶”ì¶œ
            before_parenthesis = point_name.split('(')[0]
            
            # ê³µë°±ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ë¶„ë¦¬
            words = before_parenthesis.strip().split()
            
            # ë§ˆì§€ë§‰ ë‹¨ì–´ê°€ ë²•ì •ë™
            if len(words) > 0:
                legal_dong = words[-1]
                return legal_dong.strip()
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ ì§€ì ëª… '{point_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def load_csv_data(self, csv_path):
        """CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        try:
            print(f"ğŸ“ CSV íŒŒì¼ ë¡œë“œ ì¤‘: {csv_path}")
            
            # CSV íŒŒì¼ ì½ê¸° (í•œê¸€ ì¸ì½”ë”© ì²˜ë¦¬)
            df = pd.read_csv(csv_path, encoding='utf-8')
            
            print(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í˜•íƒœ: {df.shape}")
            print(f"ğŸ“‹ ì›ë³¸ ì»¬ëŸ¼: {list(df.columns)}")
            
            # ì»¬ëŸ¼ëª… ë³€ê²½
            df = df.rename(columns=self.column_mapping)
            
            # ë²•ì •ë™ ì¶”ì¶œ ë° ì¶”ê°€
            print("ğŸ” ë²•ì •ë™ ì¶”ì¶œ ì¤‘...")
            df['legal_dong'] = df['point_name'].apply(self.extract_legal_dong)
            
            # ì¶”ì¶œ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
            print(f"ğŸ“Š ì¶”ì¶œëœ ë²•ì •ë™ ìƒ˜í”Œ:")
            sample_data = df[['point_name', 'legal_dong']].head(5)
            for idx, row in sample_data.iterrows():
                print(f"   {row['point_name']} -> {row['legal_dong']}")
            
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            try:
                # ìˆ«ìí˜• ì»¬ëŸ¼ ì²˜ë¦¬
                numeric_columns = [
                    'accident_count', 'casualty_count', 'death_count', 'serious_injury_count',
                    'minor_injury_count', 'injury_report_count', 'longitude', 'latitude'
                ]
                
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
                # BIGINT ì»¬ëŸ¼ ì²˜ë¦¬
                bigint_columns = ['accident_hotspot_fid', 'accident_hotspot_id']
                for col in bigint_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('Int64')
                
                # JSON ì»¬ëŸ¼ ì²˜ë¦¬ (í´ë¦¬ê³¤ ë°ì´í„°)
                if 'hotspot_polygon' in df.columns:
                    # JSON ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ìœ íš¨ì„± ê²€ì¦
                    def validate_polygon(polygon_str):
                        try:
                            if pd.isna(polygon_str) or polygon_str == '':
                                return None
                            # JSON íŒŒì‹± í…ŒìŠ¤íŠ¸
                            json.loads(polygon_str)
                            return polygon_str
                        except:
                            return None
                    
                    df['hotspot_polygon'] = df['hotspot_polygon'].apply(validate_polygon)
                
            except Exception as e:
                print(f"âš ï¸ ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜ (MySQLì—ì„œ ì˜¤ë¥˜ ë°©ì§€)
            df = df.where(pd.notnull(df), None)
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (pandasì—ì„œ ìƒì„±ëœ _m ì ‘ë¯¸ì‚¬ ì»¬ëŸ¼ ì œê±°)
            required_columns = [
                'accident_hotspot_fid', 'accident_hotspot_id', 'sido_code', 'point_code',
                'sido_sigungu_name', 'point_name', 'legal_dong', 'accident_count',
                'casualty_count', 'death_count', 'serious_injury_count', 'minor_injury_count',
                'injury_report_count', 'longitude', 'latitude', 'hotspot_polygon'
            ]
            
            # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
            existing_columns = [col for col in required_columns if col in df.columns]
            df = df[existing_columns]
            
            print(f"ğŸ” ì „ì²˜ë¦¬ í›„ ë°ì´í„° í˜•íƒœ: {df.shape}")
            print(f"ğŸ” ì „ì²˜ë¦¬ í›„ ì»¬ëŸ¼: {list(df.columns)}")
            
            return df
            
        except Exception as e:
            print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def save_to_database(self, df):
        """ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        try:
            print("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (í…Œì´ë¸” ì´ˆê¸°í™”)
            print("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
            with self.engine.connect() as connection:
                connection.execute(text("DELETE FROM elderly_pedestrian_accident_hotspots"))
                connection.commit()
            print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
            
            # í…Œì´ë¸”ì— ë°ì´í„° ì‚½ì…
            df.to_sql('elderly_pedestrian_accident_hotspots', 
                     con=self.engine, 
                     if_exists='append', 
                     index=False, 
                     method='multi',
                     chunksize=1000)
            
            print(f"âœ… {len(df)}ê±´ì˜ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì €ì¥ëœ ë°ì´í„° í™•ì¸
            with self.engine.connect() as connection:
                result = connection.execute(text("SELECT COUNT(*) as total FROM elderly_pedestrian_accident_hotspots"))
                total_count = result.fetchone()[0]
                print(f"ğŸ“Š ì´ ì €ì¥ëœ ë°ì´í„°: {total_count}ê±´")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise

    def run_import(self, csv_path):
        """ì „ì²´ ì„í¬íŠ¸ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            print("ğŸš€ ë…¸ì¸ ë³´í–‰ì ì‚¬ê³  ë‹¤ë°œì§€ ë°ì´í„° ì„í¬íŠ¸ ì‹œì‘")
            print("=" * 50)
            
            # 1. í…Œì´ë¸” ìƒì„±
            self.create_table()
            
            # 2. CSV ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
            df = self.load_csv_data(csv_path)
            
            # 3. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            self.save_to_database(df)
            
            print("=" * 50)
            print("ğŸ‰ ëª¨ë“  ë°ì´í„° ì„í¬íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            print(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            raise

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # CSV íŒŒì¼ ê²½ë¡œ
        csv_path = "csv/ElderlyPedestrianAccident.csv"
        
        # ì„í¬í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì‹¤í–‰
        importer = ElderlyPedestrianAccidentImporter()
        importer.run_import(csv_path)
        
    except Exception as e:
        print(f"âŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
