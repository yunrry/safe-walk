import os
import pandas as pd
import mysql.connector
from sqlalchemy import create_engine, text
from dotenv import load_dotenv
import logging
import json

# λ΅κΉ… μ„¤μ •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RiskAreaImporter:
    def __init__(self):
        """μ΄κΈ°ν™” λ° ν™κ²½λ³€μ λ΅λ“"""
        load_dotenv()
        
        # λ°μ΄ν„°λ² μ΄μ¤ μ—°κ²° μ„¤μ •
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': int(os.getenv('DB_PORT', 3306)),
            'user': os.getenv('DB_USERNAME', 'root'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'safe_walk'),
            'charset': os.getenv('DB_CHARSET', 'utf8mb4')
        }
        
        # SQLAlchemy μ—”μ§„ μƒμ„±
        connection_string = f"mysql+mysqlconnector://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}?charset={self.db_config['charset']}"
        self.engine = create_engine(connection_string)
        
        # CSV μ»¬λΌ λ§¤ν•‘ (μ‹¤μ  CSV μ»¬λΌλ… κΈ°μ¤€)
        self.column_mapping = {
            'μ—°λ„μ½”λ“': 'year_code',
            'μ‹κµ°κµ¬μ½”λ“': 'sigungu_code',
            'μ‚¬κ³ μ„ν—μ§€μ—­λ…': 'risk_area_name',
            'μ‚¬κ³ μ„ν—μ§€μ—­': 'risk_area_code',
            'μ‚¬κ³ μ„ν—μ§€μ—­ν΄λ¦¬κ³¤': 'risk_area_polygon',
            'μ΄μ‚¬κ³ κ±΄μ': 'total_accident_count',
            'μ΄μ‚¬λ§μμ': 'total_death_count',
            'μ΄μ¤‘μƒμμ': 'total_serious_injury_count',
            'μ΄κ²½μƒμμ': 'total_minor_injury_count',
            'μ΄λ¶€μƒμ‹ κ³ μμ': 'total_injury_report_count',
            'μ‚¬κ³ λ¶„μ„μ ν•λ…': 'accident_analysis_type',
            'μ¤‘μ‹¬μ utmkxμΆν‘': 'center_utmk_x',
            'μ¤‘μ‹¬μ utmkyμΆν‘': 'center_utmk_y'
        }
        
        # μ‹κµ°κµ¬ μ½”λ“ λ§¤ν•‘ (μ£Όμ” μ§€μ—­)
        self.sigungu_mapping = {
            '11110': 'μ„μΈνΉλ³„μ‹ μΆ…λ΅κµ¬',
            '11140': 'μ„μΈνΉλ³„μ‹ μ¤‘κµ¬',
            '11170': 'μ„μΈνΉλ³„μ‹ μ©μ‚°κµ¬',
            '11200': 'μ„μΈνΉλ³„μ‹ μ„±λ™κµ¬',
            '11215': 'μ„μΈνΉλ³„μ‹ κ΄‘μ§„κµ¬',
            '11230': 'μ„μΈνΉλ³„μ‹ λ™λ€λ¬Έκµ¬',
            '11260': 'μ„μΈνΉλ³„μ‹ μ¤‘λ‘κµ¬',
            '11290': 'μ„μΈνΉλ³„μ‹ μ„±λ¶κµ¬',
            '11305': 'μ„μΈνΉλ³„μ‹ κ°•λ¶κµ¬',
            '11320': 'μ„μΈνΉλ³„μ‹ λ„λ΄‰κµ¬',
            '11350': 'μ„μΈνΉλ³„μ‹ λ…Έμ›κµ¬',
            '11380': 'μ„μΈνΉλ³„μ‹ μ€ν‰κµ¬',
            '11410': 'μ„μΈνΉλ³„μ‹ μ„λ€λ¬Έκµ¬',
            '11440': 'μ„μΈνΉλ³„μ‹ λ§ν¬κµ¬',
            '11470': 'μ„μΈνΉλ³„μ‹ μ–‘μ²κµ¬',
            '11500': 'μ„μΈνΉλ³„μ‹ κ°•μ„κµ¬',
            '11530': 'μ„μΈνΉλ³„μ‹ κµ¬λ΅κµ¬',
            '11545': 'μ„μΈνΉλ³„μ‹ κΈμ²κµ¬',
            '11560': 'μ„μΈνΉλ³„μ‹ μλ“±ν¬κµ¬',
            '11590': 'μ„μΈνΉλ³„μ‹ λ™μ‘κµ¬',
            '11620': 'μ„μΈνΉλ³„μ‹ κ΄€μ•…κµ¬',
            '11650': 'μ„μΈνΉλ³„μ‹ μ„μ΄κµ¬',
            '11680': 'μ„μΈνΉλ³„μ‹ κ°•λ‚¨κµ¬',
            '11710': 'μ„μΈνΉλ³„μ‹ μ†΅νκµ¬',
            '11740': 'μ„μΈνΉλ³„μ‹ κ°•λ™κµ¬'
        }

    def create_table(self):
        """λ°μ΄ν„°λ² μ΄μ¤ ν…μ΄λΈ” μƒμ„±"""
        try:
            print("π—οΈ μ‚¬κ³  μ„ν—μ§€μ—­ ν…μ΄λΈ” μƒμ„± μ¤‘...")
            
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS risk_areas (
                id BIGINT AUTO_INCREMENT PRIMARY KEY,
                year_code INT NOT NULL COMMENT 'μ—°λ„μ½”λ“',
                sigungu_code VARCHAR(10) NOT NULL COMMENT 'μ‹κµ°κµ¬μ½”λ“',
                sigungu_name VARCHAR(50) COMMENT 'μ‹κµ°κµ¬λ…',
                risk_area_name TEXT NOT NULL COMMENT 'μ‚¬κ³ μ„ν—μ§€μ—­λ…',
                risk_area_code VARCHAR(20) NOT NULL COMMENT 'μ‚¬κ³ μ„ν—μ§€μ—­',
                risk_area_polygon TEXT COMMENT 'μ‚¬κ³ μ„ν—μ§€μ—­ν΄λ¦¬κ³¤',
                total_accident_count INT COMMENT 'μ΄μ‚¬κ³ κ±΄μ',
                total_death_count INT COMMENT 'μ΄μ‚¬λ§μμ',
                total_serious_injury_count INT COMMENT 'μ΄μ¤‘μƒμμ',
                total_minor_injury_count INT COMMENT 'μ΄κ²½μƒμμ',
                total_injury_report_count INT COMMENT 'μ΄λ¶€μƒμ‹ κ³ μμ',
                accident_analysis_type VARCHAR(200) COMMENT 'μ‚¬κ³ λ¶„μ„μ ν•λ…',
                center_utmk_x DECIMAL(15,4) COMMENT 'μ¤‘μ‹¬μ utmkxμΆν‘',
                center_utmk_y DECIMAL(15,4) COMMENT 'μ¤‘μ‹¬μ utmkyμΆν‘',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_year (year_code),
                INDEX idx_sigungu (sigungu_code),
                INDEX idx_risk_area (risk_area_code),
                INDEX idx_accident_count (total_accident_count),
                UNIQUE KEY uk_risk_area (year_code, sigungu_code, risk_area_code)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci COMMENT='μ‚¬κ³  μ„ν—μ§€μ—­ λ°μ΄ν„°';
            """
            
            with self.engine.connect() as connection:
                connection.execute(text(create_table_sql))
                connection.commit()
            
            print("β… μ‚¬κ³  μ„ν—μ§€μ—­ ν…μ΄λΈ” μƒμ„± μ™„λ£")
            
        except Exception as e:
            print(f"β ν…μ΄λΈ” μƒμ„± μ‹¤ν¨: {e}")
            raise

    def load_csv_data(self, csv_path):
        """CSV νμΌ λ΅λ“ λ° μ „μ²λ¦¬"""
        try:
            print(f"π“ CSV νμΌ λ΅λ“ μ¤‘: {csv_path}")
            
            # CSV νμΌ μ½κΈ° (ν•κΈ€ μΈμ½”λ”© μ²λ¦¬)
            df = pd.read_csv(csv_path, encoding='utf-8')
            
            print(f"π“ μ›λ³Έ λ°μ΄ν„° ν•νƒ: {df.shape}")
            print(f"π“‹ μ›λ³Έ μ»¬λΌ: {list(df.columns)}")
            
            # μ»¬λΌλ… λ³€κ²½
            df = df.rename(columns=self.column_mapping)
            
            # μ‹κµ°κµ¬ μ½”λ“λ¥Ό μ‹κµ°κµ¬λ…μΌλ΅ λ³€ν™
            df['sigungu_name'] = df['sigungu_code'].map(self.sigungu_mapping)
            
            # λ°μ΄ν„° νƒ€μ… λ³€ν™
            try:
                # μ«μν• μ»¬λΌ μ²λ¦¬
                numeric_columns = [
                    'total_accident_count', 'total_death_count', 'total_serious_injury_count',
                    'total_minor_injury_count', 'total_injury_report_count',
                    'center_utmk_x', 'center_utmk_y'
                ]
                
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
                
                # μ—°λ„ μ½”λ“ μ²λ¦¬
                if 'year_code' in df.columns:
                    df['year_code'] = pd.to_numeric(df['year_code'], errors='coerce').fillna(0).astype(int)
                
                # ν΄λ¦¬κ³¤ λ°μ΄ν„° μ²λ¦¬ (WKT ν•μ‹)
                if 'risk_area_polygon' in df.columns:
                    # WKT ν΄λ¦¬κ³¤ λ°μ΄ν„°λ¥Ό κ·Έλ€λ΅ μ €μ¥ (PostGISλ‚ κ³µκ°„ λ°μ΄ν„° μ²λ¦¬ μ‹ ν™μ© κ°€λ¥)
                    def validate_polygon(polygon_str):
                        try:
                            if pd.isna(polygon_str) or polygon_str == '':
                                return None
                            # WKT ν•μ‹ κ²€μ¦ (POLYGONμΌλ΅ μ‹μ‘ν•λ”μ§€ ν™•μΈ)
                            if polygon_str.startswith('POLYGON'):
                                return polygon_str
                            else:
                                return None
                        except:
                            return None
                    
                    df['risk_area_polygon'] = df['risk_area_polygon'].apply(validate_polygon)
                
            except Exception as e:
                print(f"β οΈ λ°μ΄ν„° νƒ€μ… λ³€ν™ μ¤‘ μ¤λ¥: {e}")
            
            # NaN κ°’μ„ NoneμΌλ΅ λ³€ν™ (MySQLμ—μ„ μ¤λ¥ λ°©μ§€)
            df = df.where(pd.notnull(df), None)
            
            print(f"π” μ „μ²λ¦¬ ν›„ λ°μ΄ν„° ν•νƒ: {df.shape}")
            print(f"π” μ „μ²λ¦¬ ν›„ μ»¬λΌ: {list(df.columns)}")
            
            return df
            
        except Exception as e:
            print(f"β CSV λ΅λ“ μ‹¤ν¨: {e}")
            raise

    def save_to_database(self, df):
        """λ°μ΄ν„°λ¥Ό λ°μ΄ν„°λ² μ΄μ¤μ— μ €μ¥"""
        try:
            print("π’Ύ λ°μ΄ν„°λ² μ΄μ¤μ— μ €μ¥ μ¤‘...")
            
            # ν…μ΄λΈ”μ— λ°μ΄ν„° μ‚½μ… (κΈ°μ΅΄ λ°μ΄ν„°λ” λ¬΄μ‹)
            df.to_sql('risk_areas', 
                     con=self.engine, 
                     if_exists='append', 
                     index=False, 
                     method='multi',
                     chunksize=1000)
            
            print(f"β… {len(df)}κ±΄μ λ°μ΄ν„°κ°€ μ„±κ³µμ μΌλ΅ μ €μ¥λμ—μµλ‹λ‹¤.")
            
            # μ €μ¥λ λ°μ΄ν„° ν™•μΈ
            with self.engine.connect() as connection:
                result = connection.execute(text("SELECT COUNT(*) as total FROM risk_areas"))
                total_count = result.fetchone()[0]
                print(f"π“ μ΄ μ €μ¥λ λ°μ΄ν„°: {total_count}κ±΄")
                
        except Exception as e:
            print(f"β λ°μ΄ν„°λ² μ΄μ¤ μ €μ¥ μ‹¤ν¨: {e}")
            raise

    def run_import(self, csv_path):
        """μ „μ²΄ μ„ν¬νΈ ν”„λ΅μ„Έμ¤ μ‹¤ν–‰"""
        try:
            print("π€ μ‚¬κ³  μ„ν—μ§€μ—­ λ°μ΄ν„° μ„ν¬νΈ μ‹μ‘")
            print("=" * 50)
            
            # 1. ν…μ΄λΈ” μƒμ„±
            self.create_table()
            
            # 2. CSV λ°μ΄ν„° λ΅λ“ λ° μ „μ²λ¦¬
            df = self.load_csv_data(csv_path)
            
            # 3. λ°μ΄ν„°λ² μ΄μ¤μ— μ €μ¥
            self.save_to_database(df)
            
            print("=" * 50)
            print("π‰ λ¨λ“  λ°μ΄ν„° μ„ν¬νΈκ°€ μ™„λ£λμ—μµλ‹λ‹¤!")
            
        except Exception as e:
            print(f"β μ„ν¬νΈ μ‹¤ν¨: {e}")
            raise

def main():
    """λ©”μΈ μ‹¤ν–‰ ν•¨μ"""
    try:
        # CSV νμΌ κ²½λ΅
        csv_path = "csv/RiskArea.csv"
        
        # μ„ν¬ν„° μΈμ¤ν„΄μ¤ μƒμ„± λ° μ‹¤ν–‰
        importer = RiskAreaImporter()
        importer.run_import(csv_path)
        
    except Exception as e:
        print(f"β ν”„λ΅κ·Έλ¨ μ‹¤ν–‰ μ‹¤ν¨: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
